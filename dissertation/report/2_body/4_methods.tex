\section{Methods}

We identified two attributes with respect to the dataset that mattered most
when implementing vertex cover (or any graph-theoretic) algorithms. These two
attributes, size and source, each bubble down to two sub-cases.

Size:

\begin{itemize}
    \item
          In-memory - The graph is small enough to store within memory. This
          means that actions can be performed such that the entire graph is
          accounted for.
    \item
          Out-of-memory - The graph is too large to store within memory in it's
          entirety. Actions must now be made on small parts of the graph
          without the knowledge of other parts.
\end{itemize}

Source:

\begin{itemize}
    \item
          Local - One has direct access to the graph, for example, in the form
          of a file.
    \item
          Networked - One does not have direct access, the data is streamed to
          you in pieces. This may be either due to the size of the data (it
          being too large to store feasibly) or due to the nature of the data.
          This nature being that the data could be fragmented across databases
          and so must be pre-processed in some way to put it all together.
\end{itemize}

These attributes allow us to break down our aims into three sections. The first
section is for in-memory sized local graphs (the traditional setting) we're
able to provide traditional tools, including visualisations and simplified
implementations using graph libraries. In this setting we can simulate
streaming by looping through the edges of a graph. This gives us a particular
advantage in seeing truly how the algorithms work as we are able to see the
entire graph at the same time.

The second section is for out-of-memory sized local graphs. In our original
plan, this section didn't exist as we assumed most implementation details would
come forward when implementing into a real streaming framework. However, we
found that this was too much of a jump so this middle step was envisioned to
allow for a true streaming implementation while still being in the familiarity
of the core Python libraries. So that's exactly what we'll be doing. Having the
graph represented by an edge list stored in a file allows us to read from the
file line-by-line and therefore edge-by-edge. This is exactly how a streaming
application would see the input of a graph. Since the time taken to read from a
file is negligible in comparison to any network activity, we will be able to
gauge the performance of these algorithms with minimal external variables. This
gives us a platform for accurate performance profiling.

The final section is for out-of-memory sized networked graphs. This is what
you'd consider to be an actual use case. As the most flexible section, in that,
there are many ways of going about it depending on your situation. We're taking
this as an opportunity to build a proof-of-concept system that covers the
basics. This allows for our fairly custom implementation of stream processing.
Most streaming platforms prioritise parallelisation in their processing which
we don't concern ourselves with. Our data source will be external in the sense
that it could be replicated to run on a server far, far away but for ease of
development it will be run locally.

\subsection{The Algorithms}

\subsubsection{Branching - Classical}

The classical branching works by starting with the whole graph and recursively
branching on each edge, deleting a chosen vertex each time. If you have a graph
with no edges before you reach a depth of \(k\) then you will have your vertex
cover. If not, then you simply try every other path down the tree, choosing a
different set of vertices on each path. If none of the paths work out then you
can conclude that no vertex cover exists with a maximum size of \(k\). The
algorithm runs in \(O(2^k \cdot n)\). The pseudocode is shown in Algorithm
\ref{alg:branching_classical}.

\begin{algorithm}[htb]
    \caption{Branching - Classical}
    \label{alg:branching_classical}
    \DontPrintSemicolon
    \SetKwFunction{FBranching}{branching}
    \SetKwFunction{FEdges}{numberOfEdges}
    \SetKwFunction{FCopy}{copy}
    \SetKwFunction{FFirstEdge}{firstEdge}

    \KwInput{Graph $graph$ to calculate vertex cover on}
    \KwInput{Value $k$ for maximum size of vertex cover}
    \KwOutput{Vertex cover of maximum size $k$ if one exists}
    \Func
    {
        \FBranching{graph, k, vertexCover $\gets \emptyset$}
    }
    {
        \uIf{\FEdges{graph} $= 0$}{
            \Return vertexCover
        }
        \uIf{k $=0$}{
            \Return \KwNull
        }
        $u, v \gets$ \FFirstEdge{graph}\;

        leftGraph $\gets$ \FCopy{graph}\;
        leftGraph $\gets$ leftGraph - u\;
        leftVertexCover $\gets$ \FCopy{vertexCover}\;
        leftVertexCover $\gets$ leftVertexCover $\cup$ \{u\}\;
        leftVertexCover $\gets$ \FBranching{leftGraph, k - 1, leftVertexCover}\;
        \uIf{leftVertexCover \KwIs \KwNot \KwNull}{
            \Return leftVertexCover
        }

        rightGraph $\gets$ \FCopy{graph}\;
        rightGraph $\gets$ rightGraph - u\;
        rightVertexCover $\gets$ \FCopy{vertexCover}\;
        rightVertexCover $\gets$ rightVertexCover $\cup$ \{u\}\;
        rightVertexCover $\gets$ \FBranching{rightGraph, k - 1, rightVertexCover}\;
        \Return rightVertexCover
    }
\end{algorithm}

Being a search tree, it is noted that this algorithm can be tweaked to be a
breadth-first search rather than depth-first. This will prioritise the search
for a minimum vertex cover which may be more useful in some situations.

\subsubsection{Branching - Stream}

The streaming branching algorithm requires \(O(k\cdot \log n)\) space and \(2^k\)
passes. It works in much the same way as the classical algorithm except,
instead of starting with the entire graph, you start with an empty vertex cover
set. If you come upon an edge that is already covered by your vertex cover then
it can be skipped. If the edge isn't covered then one of the vertices are added
to your vertex cover. Which vertex depends on the path being taken down the
tree. If you reach the end of the stream before exceeding \(k\) vertices in
your vertex cover then you have a vertex cover for the whole graph. If not,
then you try another path.

We noticed Chitnis et al had an error in their pseudocode. In their
version, if the end of the edge stream (\(j\) in their pseudocode) was reached
before a depth (\(i\) in their pseudocode) of \(k\) was reached then the
program would presumably throw an exception as there were no more edges to
read. This is due to the fact that the check for whether the end of the stream
had been reached was put outside the inner-most loop. Algorithm
\ref{alg:branching_correction} shows our corrected version. It uses the same
symbols as their paper for consistency. See symbols

\begin{algorithm}[htb]
    \caption{Branching - Stream (Corrected)}
    \label{alg:branching_correction}
    \DontPrintSemicolon

    \KwInput{Graph $graph$ to calculate vertex cover on}
    \KwInput{Value $k$ for maximum size of vertex cover}
    \KwOutput{Vertex cover of maximum size $k$ if one exists}

    Let $X = 0^k$, and suppose the edges of the graph are seen in the order $e_1, e_2, \dots, e_m$\;
    \While{X $\neq \spadesuit$}{
        $S = \emptyset, i = 1, j = 1$\;
        \While{$i \neq k + 1$}{
            Let $e_j = u - v$ such that $u < v$ under the ordering $\phi$\;
            \uIf{$u \notin S$ \KwAnd $v \notin S$}{
                \uIf{$X[i] = 0$}{
                    $S \gets S \cup \{u\}$
                }
                \uElse{
                    $S \gets S \cup \{v\}$
                }
                $i \gets i + 1$\;
            }
            $j \gets j + 1$\;
            \uIf{$j = m + 1$}{
                \Return{S}
            }
        }
        $X \gets Dictk(Next(X))$\;
    }
    \Return NO
\end{algorithm}

In implementing this algorithm, we found that the way the pseudocode had been
structured made implementation difficult. This is because streaming platforms
record whether they have seen a message or not; this is counted as the number
of \texttt{acks} (acknowledgements). If the algorithm were to exit before
acknowledging all the edges in the stream intended for it, then these edges
would lay dormant until another algorithm was run and it would start reading
them erroneously. This caused us to rewrite the algorithm with the inner-most
loop being based on looping through the edges rather than looping through the
depths of the tree. Algorithm \ref{alg:branching_stream} shows our version.

\begin{algorithm}[htb]
    \caption{Branching - Stream (Updated)}
    \label{alg:branching_stream}
    \DontPrintSemicolon
    \SetKw{KwContinue}{continue}

    \KwInput{Graph $graph$ to calculate vertex cover on}
    \KwInput{Value $k$ for maximum size of vertex cover}
    \KwOutput{Vertex cover of maximum size $k$ if one exists}

    Let $X = 0^k$, and suppose the edges of the graph are seen in the order $e_0, e_1, \dots, e_{m-1}$\;
    \While{X $\neq \spadesuit$}{
        $S = \emptyset, i = 0, j = 0$\;
        \While{$j \neq m$}{
            \uIf{$i > k$}{
                \KwContinue
            }
            Let $e_j = u - v$ such that $u < v$ under the ordering $\phi$\;
            \uIf{$u \notin S$ \KwAnd $v \notin S$}{
                \uIf{$i = k$}{
                    $i \gets i + 1$\;
                    \KwContinue
                }

                \uIf{$X[i] = 0$}{
                    $S \gets S \cup \{u\}$
                }
                \uElse{
                    $S \gets S \cup \{v\}$
                }
                $i \gets i + 1$\;
            }
            $j \gets j + 1$\;
        }
        \uIf{$i \leq k$}{
            \Return{S}
        }
        $X \gets Dictk(Next(X))$\;
    }
    \Return NO
\end{algorithm}

\subsubsection{Kernelization - Classical}

The classical kernelization algorithm works by applying the following rules
until no more reductions can be made.

\begin{enumerate}
    \item
          If \(k > 0\) and \(v\) is a vertex of degree \(> k\), remove \(v\)
          from the graph and decrease the value of \(k\) by 1.
    \item
          If \(v\) is a vertex of degree 0, remove it.
\end{enumerate}

If more than \(k^2\) edges remain in the graph, and neither of the rules can be
applied, then the graph cannot contain a vertex cover of size \(k\). On
success, the output is a kernel that has at most \(k^2\) edges and \(2k^2\)
vertices and a set of vertices that must be included in the vertex cover. The
pseudocode is given in Algorithm \ref{alg:kernelization_classical}

\begin{algorithm}[htb]
    \caption{Kernelization - Classical}
    \label{alg:kernelization_classical}
    \DontPrintSemicolon

    \SetKwFunction{FNumberOfEdges}{numberOfEdges}
    \SetKwFunction{FDegree}{degree}

    \KwInput{Graph $graph$ to calculate vertex cover on}
    \KwInput{Value $k$ for maximum size of vertex cover}
    \KwOutput{Kernel of graph and vertex cover}

    vertexCover = $\emptyset$, reductionsCanBeMade = \KwTrue\;
    \While{reductionsCanBeMade}{
        reductionMade = \KwFalse\;
        \For{node \KwIn graph.nodes}{
            \uIf{$k > 0$ \KwAnd node.\FDegree{} $> k$}{
                reductionMade $\gets$ \KwTrue\;
                graph $\gets$ graph - node\;
                vertexCover $\gets$ vertexCover $\cup$ \{node\}\;
                $k \gets k - 1$\;
            }
            \ElseIf{node.\FDegree{} $= 0$}{
                reductionMade $\gets$ \KwTrue\;
                graph $\gets$ graph - node\;
            }
        }
        \uIf{\KwNot reductionMade}{
            reductionsCanBeMade $\gets$ \KwFalse\;
        }
    }
    \uIf{graph.\FNumberOfEdges{} $> k^2$}{
        \Return \KwNull
    }
    \Return graph, vertexCover\;
\end{algorithm}

\subsubsection{Kernelization - Stream}

The streaming kernelization algorithm works by greedily maintaining a maximal
matching and for each matched vertex \(v\), keeping up to k edges incident on
\(v\). If at any point the number of matched edges exceeds \(k\) then we can
conclude no such vertex cover of size \(\leq k\) exists and end the stream. If
we reach the end of the stream then a kernel consisting of all the matched
edges and their neighbours is returned. The space complexity of this algorithm
is \(O(k^2)\). The pseudocode is given in Algorithm
\ref{alg:kernelization_stream}

\begin{algorithm}[htb]
    \caption{Kernelization - Stream}
    \label{alg:kernelization_stream}
    \DontPrintSemicolon
    \SetKwFunction{FLen}{length}
    \SetKwFunction{FGetMatch}{getMatch}
    \SetKwFunction{FIndex}{index}
    \SetKwFunction{FAppend}{append}

    \KwInput{Edges $u$, $v$ from a stream}
    \KwInput{Value $k$ for maximum size of vertex cover}
    \KwOutput{Kernel of graph}

    $maximalMatching$ = \{\}\;
    \For{u, v \KwIn stream}{
        isNeighbour $\gets$ \KwFalse\;
        \uIf{u \KwIs \KwIn maximalMatching}{
            isNeighbour $\gets$ \KwTrue\;
            matchedEdge, neighbours = maximalMatching.\FGetMatch{u}\;
            vertexPos = matchedEdge.\FIndex{u}\;
            \uIf{\FLen{neighbours[vertexPos]} $< k$}{
                matchings$[u]$.\FAppend{$(u,v)$}\;
            }
        }
        \uElseIf{v \KwIs \KwIn maximalMatching}{
            isNeighbour $\gets$ \KwTrue\;
            matchedEdge, neighbours = maximalMatching.\FGetMatch{v}\;
            vertexPos = matchedEdge.\FIndex{v}\;
            \uIf{\FLen{neighbours[vertexPos]} $< k$}{
                matchings$[v]$.\FAppend{$(u,v)$}\;
            }
        }
        \uIf{\KwNot isNeighbour}{
            maximalMatching.\FAppend{$(u,v)$}\;
            \uIf{\FLen{maximalMatching} $> k$}{
                \Return \KwNull\;
            }
        }
    }
    \Return maximalMatching\;
\end{algorithm}

\subsection{Local - Visualisation}

This is the traditional case. The graph is small enough to use in-memory and
you have local access to it, so you are able to use which ever tools you wish
to calculate the vertex cover. We will be using a library called NetworkX
\cite{hagberg2008exploring}. NetworkX provides data structures for graphs with
an intuitive API. It also includes a module for drawing graphs with Matplotlib
\cite{hunter2007matplotlib}, a Python visualization library that has been
around since 2003 \cite{matplotlib2003copyright}. With these tools we will be
able to create programs that create visualisations of both the kernelization
and branching stream algorithms.

There are some key aspects we'd like to highlight in both algorithms. For the
kernelization algorithm, these include being able to compare the kernel to the
whole graph and being able to see when edges are not added to the kernel. For
the branching algorithm, these include the binary string and the binary search
tree.

\subsection{Local-Stream - Performance Benchmarking}

In this case the graph is no longer large enough to store in-memory but you are
able to have direct access to it. The graph may be large but it is feasible to
store the graph on disk since disk size is often many magnitudes larger than
that of memory. Traditional algorithms are no longer applicable here, this is
the first example where the invention of streaming algorithms is a necessity.

In order to properly performance benchmark the algorithms, we will have to do
both runtime analysis and memory profiling to get an accurate picture of how
they perform.

While the original intention for this section of the project was to test
against large graphs from all possible backgrounds
(constructed/synthetic/real), we quickly realised that many, if not all, graphs
we considered were of the same shape/form. That is, they all had relatively
uniform density and so had a minimum vertex cover close to the number of
vertices. In order to get any results that was anything more than a null
result, we would have to generate some graphs of our own. These graphs would
have to have a large number of edges while simultaneously having a low vertex
cover number. This leads to graphs with a low level of connectivity.

For memory profiling, we will use the Python package \texttt{memory-profiler}
which records memory usage at intervals of \(0.1\text{s}\). It also allows for
tagging of functions meaning that we can see when each function starts and
ends. Creating a script to run both the local and stream versions of each
algorithm will allow us to show the memory usage of each side-by-side.

For runtime analysis, we will use a Python package called \texttt{pyperf}. It
includes tools for writing, running, and analysing runtime benchmarks. By
creating a script to run through a handful of graphs and \(k\) values and
running them with both the local and stream versions of each algorithm, we
should be able to paint a clearer picture of how the stream versions compare to
their local counterparts.

\subsection{Stream - Implementation}

This is the main case. In a typical situation, knowledge of the graph's
attributes will be limited so it should be treated as an unbounded stream (a
stream that has no end). The opposite of this would be treating it as a bounded
stream, which we know has an end.

Most streaming applications work on unbounded streams. These are data streams
which are essentially infinite. Examples include sensor readings and
application logging. In these cases, the objective is not to obtain a final
result, rather to aggregate the data before storing it for future use. This
would be classed as stream processing. Specifically, the Vertex Cover problem
would be classed as batch processing. We may be working on a data stream but
once either algorithm has completed we won't need to run it again.

Most streaming platforms (especially those in the Apache line up) mainly work
on unbounded stream processing but can be tweaked to also handle batch
processing. At their base, these streaming platforms are just messaging
platforms that have been built to be fault-tolerant and capable of handling
masses of data at any one time. These facilitate the data stream transmission.
Examples include:

\begin{itemize}
    \item
          Apache Kafka
    \item
          Amazon Kinesis
    \item
          Google Cloud Pub/Sub
    \item
          RabbitMQ
\end{itemize}

Once we have the platform, we need an in-memory framework to handle the
processing of each item in the stream. This is where the algorithms will
actually run. There are a number of graph-specific processing frameworks,
however these perform higher-level algorithms than the ones we are building
here. Also, many have a focus on being distributed (read: parallelised) which
is also something we're not interested in. Since we plan to write the other two
sections in Python, it would make sense to continue as such. Faust is a Python
stream processing library built for use with Apache Kafka so is a perfect
candidate for us.

There is another problem to tackle in this case which is the role of the data
source. For the algorithms we will be implementing, it must be able to handle
requests for graphs to be streamed to the stream processor. This rules out
simply linking up a database as that wouldn't have the capability. A server is
most likely needed to handle the requests as well as facilitate getting the
data from storage and sending it through the streaming platform.

There is the fourth case based on the dataset's attributes in which the size of
the graph is an in-memory size but comes from a networked source. If you know
beforehand that the graph is an in-memory size then you don't need to go
through the hassle of treating it as a stream. One pass through the graph will
allow you to store the graph locally and therefore be able to use it as a local
graph instead.
