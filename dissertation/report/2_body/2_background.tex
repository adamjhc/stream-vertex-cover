\section{Background}

For the reader unfamiliar with concepts covered in this paper, a definition has
been provided for each.

\textbf{Graph Theory}: The study of mathematical structures (graphs) made up of
vertices and edges which are used to show pairwise relations between objects.

\textbf{Vertex Cover} (VC): A set of vertices such that each edge of a graph is
incident to at least one vertex in the set. Formally, given a graph \(G = (V,
E)\) and a vertex cover \(V'\):
\[
    V' \subset V \text{ such that } \forall (u, v) \in E \Rightarrow u \in V' \vee v \in V'
\]

\textbf{Maximal Matching}: A matching in a graph is a set of edges without a
common vertex. A maximal matching is a matching that cannot get any bigger. A
maximum matching is also a maximal matching, but not all maximal matchings are
maximum matchings.

\textbf{Parameterized Complexity}: A branch of complexity theory concerning
decision problems parameterized by one or more values with respect to the input
or output.

\textbf{Fixed-Parameter Tractable} (FPT): A subset of parameterized problems.
Those that can be solved by algorithms in time \(f(k)n^{O(1)}\), where \(n\) is
the input size, \(k\) is the parameter, and \(f\) is an arbitrary function.

\textbf{Parameterized Vertex Cover}: Also known as k-VC, the vertex cover
problem is posed as a decision problem in which we are given a graph \(G\) and
a positive integer \(k\) and we must find out whether \(G\) has a vertex cover
of size at most \(k\).

\textbf{Streaming Algorithm}: An algorithm designed for processing streams of
data while using only a constant amount of memory.

\textbf{Kernelization}: A pre-processing method for minimising datasets into
their core components which is known as a kernel. Processing completed on such
a kernel will return the same output that would be returned had the processing
been run on the entire dataset. A parameterized problem is in FPT if it has a
kernel.

\textbf{Branching}: A tree-based method for searching for solutions in a
problem space. Trees provide relatively easy logarithmic complexity, because
they split their data into \(n\) sections recursively, and are simple to
understand and implement.
